{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f648a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e96749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2: naive bayes class\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.feature_probs = {}\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            X_c = X[y == cls]\n",
    "            self.class_priors[cls] = X_c.shape[0] / n_samples\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            X_c = X[y == cls]\n",
    "            self.feature_probs[cls] = {}\n",
    "            \n",
    "            for feature_idx in range(n_features):\n",
    "                feature_values = np.unique(X[:, feature_idx])\n",
    "                self.feature_probs[cls][feature_idx] = {}\n",
    "                \n",
    "                for value in feature_values:\n",
    "                    count = np.sum(X_c[:, feature_idx] == value)\n",
    "                    total = X_c.shape[0]\n",
    "                    self.feature_probs[cls][feature_idx][value] = (count + 1) / (total + len(feature_values))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        probabilities = np.zeros((n_samples, len(self.classes)))\n",
    "        \n",
    "        for idx, sample in enumerate(X):\n",
    "            for cls_idx, cls in enumerate(self.classes):\n",
    "                log_prob = np.log(self.class_priors[cls])\n",
    "                \n",
    "                for feature_idx in range(n_features):\n",
    "                    feature_value = sample[feature_idx]\n",
    "                    feature_probs = self.feature_probs[cls][feature_idx]\n",
    "                    likelihood = feature_probs.get(feature_value, 1e-6)\n",
    "                    log_prob += np.log(likelihood)\n",
    "                \n",
    "                probabilities[idx, cls_idx] = log_prob\n",
    "        \n",
    "        probabilities = np.exp(probabilities)\n",
    "        probabilities /= probabilities.sum(axis=1, keepdims=True)\n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return self.classes[np.argmax(probabilities, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE SUCCESS PREDICTION USING NAIVE BAYES\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_file = \"../30movies_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f\"Dataset loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7baf23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY STATISTICS (UNIQUE WORDS IN TITLES)\n",
      "Vocabulary size: 57\n",
      "Sample words: ['rises', 'dune', 'maverick', 'amadeus', 'road', 'whispering', 'water', 'knight', 'the', 'wall', 'last', 'laughing', 'street', 'get', 'max:', 'eternal', 'blue', 'dark', 'iron', 'gravity'] ...\n",
      "Total records: 30\n",
      "\n",
      "Columns: ['Title', 'Year', 'Genre', 'Director', 'Lead Actor', 'Production Company', 'Runtime (min)', 'Country of Origin', 'Original Language', 'Gross Revenue (million)', 'Success']\n"
     ]
    }
   ],
   "source": [
    "# here convert all titles to lowercase, split into words, collect into a set\n",
    "vocab = set()\n",
    "for title in df['Title']:\n",
    "    words = title.lower().split()\n",
    "    vocab.update(words)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"VOCABULARY STATISTICS (UNIQUE WORDS IN TITLES)\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Sample words: {list(vocab)[:20]} ...\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944e37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after removing missing values: 30 (removed 0)\n",
      "Total movies: 30\n",
      "Successful movies (revenue >= mean): 9 (30.0%)\n",
      "Unsuccessful movies (revenue < mean): 21 (70.0%)\n",
      "Mean revenue: $416.58\n"
     ]
    }
   ],
   "source": [
    "# cell 5: creating Success Label and Clean Data\n",
    "mean_revenue = df['Gross Revenue (million)'].mean()\n",
    "df['Success'] = (df['Gross Revenue (million)'] >= mean_revenue).astype(int)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_original_size = len(df)\n",
    "df = df.dropna()\n",
    "print(f\"\\nRows after removing missing values: {len(df)} (removed {df_original_size - len(df)})\")\n",
    "print(f\"Total movies: {len(df)}\")\n",
    "print(f\"Successful movies (revenue >= mean): {df['Success'].sum()} ({df['Success'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"Unsuccessful movies (revenue < mean): {len(df) - df['Success'].sum()} ({(len(df) - df['Success'].sum())/len(df)*100:.1f}%)\")\n",
    "print(f\"Mean revenue: ${mean_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36914841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Genres: 26\n",
      "Unique Directors: 24\n",
      "Unique Lead Actors: 27\n",
      "Unique Production Companies: 21\n",
      "Unique Countries: 13\n",
      "Unique Languages: 4\n"
     ]
    }
   ],
   "source": [
    "label_encoder_genre = df[['Genre']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_genre['GenreId'] = label_encoder_genre.index\n",
    "genre_to_id = dict(zip(label_encoder_genre['Genre'], label_encoder_genre['GenreId']))\n",
    "print(f\"Unique Genres: {len(genre_to_id)}\")\n",
    "\n",
    "label_encoder_director = df[['Director']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_director['DirectorId'] = label_encoder_director.index\n",
    "director_to_id = dict(zip(label_encoder_director['Director'], label_encoder_director['DirectorId']))\n",
    "print(f\"Unique Directors: {len(director_to_id)}\")\n",
    "\n",
    "label_encoder_actor = df[['Lead Actor']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_actor['ActorId'] = label_encoder_actor.index\n",
    "actor_to_id = dict(zip(label_encoder_actor['Lead Actor'], label_encoder_actor['ActorId']))\n",
    "print(f\"Unique Lead Actors: {len(actor_to_id)}\")\n",
    "\n",
    "label_encoder_production = df[['Production Company']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_production['ProductionId'] = label_encoder_production.index\n",
    "production_to_id = dict(zip(label_encoder_production['Production Company'], label_encoder_production['ProductionId']))\n",
    "print(f\"Unique Production Companies: {len(production_to_id)}\")\n",
    "\n",
    "label_encoder_country = df[['Country of Origin']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_country['CountryId'] = label_encoder_country.index\n",
    "country_to_id = dict(zip(label_encoder_country['Country of Origin'], label_encoder_country['CountryId']))\n",
    "print(f\"Unique Countries: {len(country_to_id)}\")\n",
    "\n",
    "label_encoder_language = df[['Original Language']].drop_duplicates().reset_index(drop=True)\n",
    "label_encoder_language['LanguageId'] = label_encoder_language.index\n",
    "language_to_id = dict(zip(label_encoder_language['Original Language'], label_encoder_language['LanguageId']))\n",
    "print(f\"Unique Languages: {len(language_to_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d5339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed data saved to: 'processed_movies_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: appling encoding to dataframe\n",
    "df['GenreId'] = df['Genre'].map(genre_to_id)\n",
    "df['DirectorId'] = df['Director'].map(director_to_id)\n",
    "df['ActorId'] = df['Lead Actor'].map(actor_to_id)\n",
    "df['ProductionId'] = df['Production Company'].map(production_to_id)\n",
    "df['CountryId'] = df['Country of Origin'].map(country_to_id)\n",
    "df['LanguageId'] = df['Original Language'].map(language_to_id)\n",
    "\n",
    "df.to_csv('processed_movies_data.csv', index=False)\n",
    "print(\"\\nProcessed data saved to: 'processed_movies_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a698a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREVIEW\n",
      "                      Title  Year                  Genre  \\\n",
      "0  The Grand Budapest Hotel  2014           Comedy-Drama   \n",
      "1                  Parasite  2019  Thriller, Dark Comedy   \n",
      "2                      1917  2019             War, Drama   \n",
      "3        Mad Max: Fury Road  2015         Action, Sci-Fi   \n",
      "4                La La Land  2016       Musical, Romance   \n",
      "5                   Get Out  2017       Horror, Thriller   \n",
      "6              The Revenant  2015       Adventure, Drama   \n",
      "7                      Coco  2017   Animation, Adventure   \n",
      "8                      Dune  2021      Sci-Fi, Adventure   \n",
      "9        The Shape of Water  2017         Fantasy, Drama   \n",
      "\n",
      "                Director  Success  Gross Revenue (million)  \n",
      "0           Wes Anderson        0                    174.8  \n",
      "1           Bong Joon-ho        0                    258.8  \n",
      "2             Sam Mendes        0                    384.9  \n",
      "3          George Miller        0                    378.9  \n",
      "4        Damien Chazelle        1                    446.1  \n",
      "5           Jordan Peele        0                    255.5  \n",
      "6  Alejandro G. Iñárritu        1                    533.0  \n",
      "7            Lee Unkrich        1                    807.8  \n",
      "8       Denis Villeneuve        0                    402.0  \n",
      "9     Guillermo del Toro        0                    195.2  \n",
      "TRAIN-TEST SPLIT\n",
      "Training samples: 24 (80.0%)\n",
      "Testing samples: 6 (20.0%)\n",
      "Number of features: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA PREVIEW\")\n",
    "print(df[['Title', 'Year', 'Genre', 'Director', 'Success', 'Gross Revenue (million)']].head(10))\n",
    "\n",
    "feature_columns = ['Year', 'GenreId', 'DirectorId', 'ActorId', 'ProductionId', 'Runtime (min)', 'CountryId', 'LanguageId']\n",
    "X = df[feature_columns].values\n",
    "y = df['Success'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f7194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PERFORMANCE METRICS\n",
      "Accuracy: 0.6667 (66.67%)\n",
      "Precision: 0.3333\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.5000\n",
      "CONFUSION MATRIX\n",
      "[[3 2]\n",
      " [0 1]]\n",
      "\n",
      "Interpretation:\n",
      "True Negatives (Correctly predicted unsuccessful): 3\n",
      "False Positives (Incorrectly predicted successful): 2\n",
      "False Negatives (Incorrectly predicted unsuccessful): 0\n",
      "True Positives (Correctly predicted successful): 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"True Negatives (Correctly predicted unsuccessful): {conf_matrix[0][0]}\")\n",
    "print(f\"False Positives (Incorrectly predicted successful): {conf_matrix[0][1]}\")\n",
    "print(f\"False Negatives (Incorrectly predicted unsuccessful): {conf_matrix[1][0]}\")\n",
    "print(f\"True Positives (Correctly predicted successful): {conf_matrix[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f48c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not Successful       1.00      0.60      0.75         5\n",
      "    Successful       0.33      1.00      0.50         1\n",
      "\n",
      "      accuracy                           0.67         6\n",
      "     macro avg       0.67      0.80      0.62         6\n",
      "  weighted avg       0.89      0.67      0.71         6\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not Successful       1.00      0.60      0.75         5\n",
      "    Successful       0.33      1.00      0.50         1\n",
      "\n",
      "      accuracy                           0.67         6\n",
      "     macro avg       0.67      0.80      0.62         6\n",
      "  weighted avg       0.89      0.67      0.71         6\n",
      "\n",
      "All predictions saved to: 'movie_success_predictions_naive_bayes.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"CLASSIFICATION REPORT\")\n",
    "class_report = classification_report(y_test, y_pred, target_names=['Not Successful', 'Successful'])\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "id_to_genre = {v: k for k, v in genre_to_id.items()}\n",
    "id_to_director = {v: k for k, v in director_to_id.items()}\n",
    "id_to_actor = {v: k for k, v in actor_to_id.items()}\n",
    "id_to_production = {v: k for k, v in production_to_id.items()}\n",
    "id_to_country = {v: k for k, v in country_to_id.items()}\n",
    "id_to_language = {v: k for k, v in language_to_id.items()}\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "df_test['success_probability'] = y_pred_proba[:, 1]\n",
    "df_test['predicted_success'] = y_pred\n",
    "df_test['actual_success'] = y_test\n",
    "\n",
    "df_test['Genre'] = df_test['GenreId'].map(id_to_genre)\n",
    "df_test['Director'] = df_test['DirectorId'].map(id_to_director)\n",
    "df_test['Lead Actor'] = df_test['ActorId'].map(id_to_actor)\n",
    "df_test['Production Company'] = df_test['ProductionId'].map(id_to_production)\n",
    "df_test['Country'] = df_test['CountryId'].map(id_to_country)\n",
    "df_test['Language'] = df_test['LanguageId'].map(id_to_language)\n",
    "\n",
    "results_df = df_test[['Year', 'Genre', 'Director', 'Lead Actor', 'Production Company', 'Runtime (min)', \n",
    "                       'Country', 'Language', 'success_probability', 'predicted_success', 'actual_success']].copy()\n",
    "\n",
    "results_df['correct_prediction'] = (results_df['predicted_success'] == results_df['actual_success']).astype(int)\n",
    "\n",
    "\n",
    "class_report = classification_report(y_test, y_pred, target_names=['Not Successful', 'Successful'])\n",
    "print(class_report)\n",
    "print(\"All predictions saved to: 'movie_success_predictions_naive_bayes.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bffc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ANALYSIS\n",
      "Total test samples: 6\n",
      "Predicted Successful: 3\n",
      "Actually Successful: 1\n",
      "Correct Predictions: 4 (66.7%)\n",
      "Incorrect Predictions: 2 (33.3%)\n",
      "Correctly Predicted as Successful: 1\n",
      "   Year              Genre            Director         Lead Actor  success_probability  predicted_success  actual_success  correct_prediction\n",
      "1  2012   Action, Thriller   Christopher Nolan     Christian Bale             0.921640                  1               1                   1\n",
      "2  2018            Fantasy  Guillermo del Toro      Maribel Verdú             0.583333                  1               0                   0\n",
      "3  2014       Drama, Music     Damien Chazelle       Miles Teller             0.536766                  1               0                   0\n",
      "5  2017     Fantasy, Drama  Guillermo del Toro      Sally Hawkins             0.424084                  0               0                   1\n",
      "0  2014          Biography         James Marsh       Kate Winslet             0.260526                  0               0                   1\n",
      "4  2021  Sci-Fi, Adventure    Denis Villeneuve  Timothée Chalamet             0.096894                  0               0                   1\n",
      "\n",
      "Top 10 predictions saved to: 'top_10_success_predictions.csv'\n",
      "Average probability for CORRECT predictions: 0.4258\n",
      "Average probability for INCORRECT predictions: 0.5600\n",
      "1. processed_movies_data.csv - Processed dataset with encodings\n",
      "2. movie_success_predictions_naive_bayes.csv - All predictions\n",
      "3. top_10_success_predictions.csv - Top 10 most likely successful movies\n",
      "4. correct_predictions.csv - Correctly predicted movies\n",
      "5. incorrect_predictions.csv - Incorrectly predicted movies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"PREDICTION ANALYSIS\")\n",
    "successful_predicted = results_df[results_df['predicted_success'] == 1]\n",
    "successful_actual = results_df[results_df['actual_success'] == 1]\n",
    "correct_predictions = results_df[results_df['correct_prediction'] == 1]\n",
    "\n",
    "print(f\"Total test samples: {len(results_df)}\")\n",
    "print(f\"Predicted Successful: {len(successful_predicted)}\")\n",
    "print(f\"Actually Successful: {len(successful_actual)}\")\n",
    "print(f\"Correct Predictions: {len(correct_predictions)} ({len(correct_predictions)/len(results_df)*100:.1f}%)\")\n",
    "print(f\"Incorrect Predictions: {len(results_df) - len(correct_predictions)} ({(len(results_df) - len(correct_predictions))/len(results_df)*100:.1f}%)\")\n",
    "\n",
    "correct_successful = results_df[(results_df['predicted_success'] == 1) & (results_df['actual_success'] == 1)]\n",
    "print(f\"Correctly Predicted as Successful: {len(correct_successful)}\")\n",
    "\n",
    "\n",
    "top_predictions = results_df.nlargest(10, 'success_probability')\n",
    "print(top_predictions[['Year', 'Genre', 'Director', 'Lead Actor', 'success_probability', \n",
    "                        'predicted_success', 'actual_success', 'correct_prediction']].to_string())\n",
    "\n",
    "top_predictions.to_csv('top_10_success_predictions.csv', index=False)\n",
    "print(\"\\nTop 10 predictions saved to: 'top_10_success_predictions.csv'\")\n",
    "\n",
    "\n",
    "correct_pred_df = results_df[results_df['correct_prediction'] == 1]\n",
    "incorrect_pred_df = results_df[results_df['correct_prediction'] == 0]\n",
    "\n",
    "\n",
    "if len(correct_pred_df) > 0:\n",
    "    print(f\"Average probability for CORRECT predictions: {correct_pred_df['success_probability'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"No correct predictions found\")\n",
    "\n",
    "if len(incorrect_pred_df) > 0:\n",
    "    print(f\"Average probability for INCORRECT predictions: {incorrect_pred_df['success_probability'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"No incorrect predictions found\")\n",
    "\n",
    "correct_pred_df.to_csv('correct_predictions.csv', index=False)\n",
    "incorrect_pred_df.to_csv('incorrect_predictions.csv', index=False)\n",
    "\n",
    "print(\"1. processed_movies_data.csv - Processed dataset with encodings\")\n",
    "print(\"2. movie_success_predictions_naive_bayes.csv - All predictions\")\n",
    "print(\"3. top_10_success_predictions.csv - Top 10 most likely successful movies\")\n",
    "print(\"4. correct_predictions.csv - Correctly predicted movies\")\n",
    "print(\"5. incorrect_predictions.csv - Incorrectly predicted movies\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
